---
title: "Reading Log"
author: "Joe Shaw"
format: html
bibliography: references.bib
csl: harvard-manchester-metropolitan-university.csl
---

# "Excuse Me, Do You Have a Moment to Talk About Version Control?" [@bryan2018]

"Git was built neither for the exact usage described here, nor for broad usability. You will undoubtedly notice this, so it is best to know in advance."

"Git is a version control system. Its original purpose was to help groups of developers work collaboratively on big software projects. Git manages the evolution of a set of files—called a repository or repo—in a sane, highly structured way. It is like the “Track Changes” feature from Microsoft Word, but more rigorous, powerful, and scaled up to multiple files."

"Many people who do not use Git unwittingly reinvent a poor man’s version of it"

"With informal version control, contributors create derivative copies of iris.R, decorating the file name with initials, dates, and other descriptors. Even when working alone, this leads to multiple versions of iris.R of indeterminate relatedness (Figure 1(a)). In collaborative settings based on email distribution, the original file swiftly becomes part of a complicated phylogeny that no amount of “Track changes” and good intentions can resolve"

"GitHub is like DropBox or Google Drive, but more structured, powerful, and programmatic."

"There is a taboo against committing derived products, inherited from Git’s software development roots, because the typical product in that context is a platform-specific executable. This rationale, however, does not apply to many data science products. Rendered reports, figures, and cleaned data are often extremely valuable to others. Make them readily available."

"If a file is binary, such as a Word document or Excel spreadsheet, you will not get human-readable diffs anyway, nor can GitHub display the content in the browser."

"What is a merge conflict? It happens when Git cannot be certain how to jointly apply the diffs from two different commits to their common parent. At each location of conflict, you must pick one version or the other – or create a hybrid—and mark it as resolved."

# "Packaging data analytical work reproducibly using R (and friends)" [@marwick2018]

"Virtually all researchers use computers as a central tool in their workflow. However, our
formal education rarely includes any training in how to organise our computer files to make
it easy to reproduce results and share our entire analysis pipeline with others."

"Although the R packaging system is traditionally a method for sharing statistical
methods, we claim that R packages are suitable for use as research compendia that can
help improve computational reproducibility."

Compendium: a short but complete summary.

"Once you are ready to share your compendium, the best way is to archive a specific
commit at a repository that issues persistent URLs, such as a Digital Object Identifier DOI), for file archives (e.g. osf.io, figshare.com or zenodo.org). DOIs are designed to be
far more persistent than other URLs, which often break as web pages change over time."

"While CRAN is one of the biggest and best-known systems for archiving and distributing
R packages, we do not recommend it for research compendium packages. The main reason
that CRAN is not suitable is that it is very strict about the directory structure and contents
for the R packages that it accepts."

This is really useful paper. The premise is that structuring scientific research projects as if they were R packages leads to more reproducible research. This also makes sense in the context of laboratory test validations: what I want is a clear structure to organise a project so that I can put the entire thing somewhere public and say "this is what I did". Their term for this is a "research compendium": the summary of the entire project.

The paper also includes this Github template: https://github.com/cboettig/template

The template is for how to structure an academic paper like an R package, with these folders:

- **R**: contains all functions as .R files.

- **man**: contains documentation for functions using roxygen2.

- **tests**: contains all the tests run during package building.

- **vignettes**: the place for the actual manuscript as a markdown files (RMarkdown, Quarto etc) - this means the manuscript and analysis are fused together as one.

# "Welcome to the Tidyverse" [@wickham2019]

"At a high level, the tidyverse is a language for solving data science challenges with R code. Its
primary goal is to facilitate a conversation between a human and a computer about data."

"Non-core packages are installed with install.packages("tidyverse"), but are not at-
tached by library(tidyverse)." - this explains why you have to use library(lubdridate) - lubridate is technically in the tidyverse but is non-core.

"There is one particularly important principle that we want to call out here: the tidyverse is fundamentally  human centred. That is, the tidyverse is designed to support the activities of a human data analyst, so to be effective tool builders, we must explicitly recognise and acknowledge the strengths and weaknesses of human cognition."

"The tidyverse is not just the collection of packages — it is also the community of people who use them. We want the tidyverse to be a diverse, inclusive, and welcoming community."

# Novo Nordisk's Journey to an R based FDA Submission - [YouTube]()

R packages are great, but they present issues for good practice when it comes to pharmaceutical submissions. This is because pharmaceutical submissions are usually submitted in SAS, and changing the format means learning for the submitter and the regulatory body reviewing the work.

They set up a Shiny interface for people to request an R package to be made available within the company's R environment.

### Acronyms and terms:

**Novo Nordisk:** pharmaceutical company

**GxP:** "good practice" (i.e GMP - Good Manufacturing Practice)

**SAS:** statistical language normally used for pharmaceutical submissions (Statistical Analysis System).

**Azure (Microsoft Azure):** cloud-computing service provided by Microsoft.

**AWS:** Amazon Web Solutions.

**Kubernetes:** a system for automating software development, initially developed by Google. "Kubernetes" comes from the Greek word for "helmsman" - i.e. Kubernetes steers the ship for you.

**TFL:** Tables, Figures and Listings

**SDTM:** Study Data Tabulation Model 

**ADaM:** Analysis Data Model (see [this link](https://www.certara.com/blog/demystifying-cdisc-sdtm-and-adam/))

# Jenny Bryan "Object of type ‘closure’ is not subsettable" - [Posit](https://posit.co/resources/videos/object-of-type-closure-is-not-subsettable/)

```{r}
#| label: object-type-closure-error
#| error: TRUE
#| include: TRUE
#| warning: FALSE

# You define "dat" as a data frame
dat <- data.frame(x = 1, y = 2)

# You forget that you named it "dat" and instead think you named it "df".
# "df" is actually a function, so you're asking R to give you column x of a function (which it can't do)
df$x

```

Rules for debugging errors.

**Restart R regularly**

Use the shortcut to restart R (Control+shift+F10), rather than using rm(list = ls()) - some things will still persist after running rm(list=ls()) because it only clears the environment.
For example, library(dplyr) will mean that dplyr remains attached even after the environment is cleared.

Restarting R works best when you have the options set to not save or reload the workspace.

**Reprex**

Create small reproducible examples (reprexes).

The distinction between beginners and experts is how they respond to bugs. Experts run small experiments to pick apart problems.

The problem usually lies in the difference between what you *think* you are doing, and what you are *actually* doing.

"If you are trying to find a needle in a haystack, try looking in a smaller haystack" - make the reproducible example *minimal*.

Define the data (in-line) rather than having private data that you run. Simplify the data to the minimum required to replicate the error message.

Don't attach additional packages that aren't necessary to creating the error.

Making a reprex is a way to help you solve your own problem.

**Debug**

Debugging really has 3 modes: traceback (the death certificate), options(error = recover) (the post-mortem) and browser() (resurrecting the dead to establish what happened).

browser() allows you run the code line by line and watch how the environment changes. You can also change the identity of variables mid-way through, if you have a theory about why the error is occurring (if the error then dissapears, you've found the cause).

Hit capital Q (cpaslock + q) to get out of the browser debugger.

**Deter**

After debugging, add an assertion to your code to catch the error in future.

Write error messages for humans. "Object of type closure is not subsettable" is less understandable than "Can't subset a function".

Build things in a way so that when they break it is clear why.

# The Past and Future of Shiny - Joe Cheng [Posit](https://shiny.posit.co/blog/posts/the-past-and-future-of-shiny-joe-cheng/)

manipulate function in RStudio was a precursor to Shiny: interactive plots within RStudio.

Making user interfaces is hard. It's easier to give people tools. 

The key decision was to use R to write the client and the server, rather than a combination of HTML and R (they didn't want people to have to learn HTML or JavaScript).

Writing web-apps is very different to data analysis.

In 2012, people were suspicious of RStudio - it's free, there's no premium version - what's the catch?

## Why is R a good language for Shiny?

Positional and named arguments: a positional argument is determined by it's position in the function call, whereas a named argument has a name.

Example: f(data, input = 1)

data is a positional argument (it is first) whereas input is a named argument.

Python, Ruby and C# all take positional arguments before named arguments, but R can do both. This made R much better for building Shiny apps.

"R is the best language for Shiny. Python is the second-best language for anything."

# R: A Language for Data Analysis and Graphics [@ihaka1996]

"The work has been heavily influenced by two existing languages-Becker, Chambers, and Wilks' S (1985) and Steel and Sussman's Scheme (1975). We felt that there were strong points in each of these languages and that it would be interesting to see if the strengths could be combined. The resulting language is very similar in appearance to S, but the underlying implementation and semantics are derived from Scheme."

"The development of the key portions of language took two years of part-time effort on our part."

"We have named our language R-in part to acknowledge the influence of S and in part to celebrate our own efforts. Despite what has been a nearly all-consuming effort, we have managed to remain on the best of terms and retain our interest in computers and computing."

"The language-that is, syntax and semantics-plus the tools are combined into what can be called the run-time environment.This environment is the typical user's view of the program.Users want a language that is not only flexible but also provides them with a variety of tools for performing computations"

"an expression written in a computer language is not sufficient in itself to define the value to be returned by a computation.In addition,values must be associated with the symbols that appear in the expression. In both Scheme and S the association between symbols and values is provided by what we will call an *environment*. An environment consists of a list of environment frames, each of which can be thought of as a list of symbol/value pairs."

The way in which R executes a function and looks for variables which aren't defined in the function body (scoping) is different to S. R instead uses an evaluation model from Scheme. This is a bit confusing but the simplest way to illustrate it is with an example:

```{r}
#| label: r-scoping
#| include: TRUE

y <- 123

f <- function(x) {
  
  y <- x * x
  
  g <- function() print(y)
  
  g()
  
}

# In R, this returns 100, because the function evaluates y <- x*x within 
# the function call and uses this value when returning y.
f(10)

# In S, the same call returns 123.

```

Another difference is that Scheme uses *eager evaluation* whereas S uses *lazy evaluation*, and R inherits lazy evaluation from S. In eager evaluation, all the arguments to a function are evaluated before the main body of the function, whereas lazy evaluation only evaluates an argument if required by the function body.

# "Facets of R" [@chambers2009]

"We are seeing today a widespread, and welcome, tendency for non-computer-specialists among statisticians and others to write collections of R functions that organize and communicate their work. Along with the flood of software sometimes comes an attitude that one need only learn, or teach, a sort of basic how-to-write-the-function level of R programming, beyond which most of the detail is unimportant or can be absorbed without much discussion. **As delusions go, this one is not very objectionable if it encourages participation. Nevertheless, a delusion it is.**"

"During the 1980s the topics of functional programming and object-oriented programming stimulated growing interest in the computer science literature."

"The functional and object-oriented facets were combined in S and R, but they appear more frequently in separate, incompatible languages."

"The larger module introduced by R is probably the most important for the system’s growing use, the package. As it has evolved, and continues to evolve, an R package is a module combining in most cases R functions, their documentation, and possibly data objects and/or code in other languages."

"One is that, being an open-source system, R is generally able to incorporate other open-source software and does indeed do so in many areas. In contrast, proprietary systems are more likely to build extensions internally, either to maintain competitive advantage or to avoid the free distribution requirements of some open-source licenses. "

# Colin Gillespie: R Security [UseR Conference](https://www.youtube.com/watch?v=5odJxZj9LE4)

The weakest point in any system is usually the human: people mis-type URLS and make passwords that are very easy to guess.

# Joe Cheng: Shiny's Holy Grail - interactivity with reproducibility [useR! conference 2019](https://www.youtube.com/watch?v=5KByRC6eqC8)

The problem is that specific uses of Shiny apps aren't reproducible - you have to perform the same manual actions as someone else.

The goal therefore was to allow the user to interact with a Shiny app, find a view that they liked, then download a zip file which includes the Shiny code, a PDF of the app's view and any necessary data.

The aim is to reverse-engineer Shiny. To make a Shiny app you take an R script, then add specific features to make it into an app. The aim now is to take Shiny app code and reverse it back into an R script.

There are different ways of doing this, but the solution they picked was to write code that serves two purposes: Shiny execution AND exporting static code - this can be done using the shinymeta package.

"Scientists build to learn, engineers learn to build."

Reactive code needs to be made static - you are taking a snapshot of the app's use. You can use the bang-bang !! operator for this.

The workflow is:

- A coder writes a shiny app using the shinymeta package with special shinymeta functions

- When the app is rendered the R code is converted into Javascript and HTML to render the app

- A user interacts with the and changes the view or data or whatever

- The user then hits a button, and the state of the app is frozen. The Shiny code is reversed back to a logical series of R code chunks which show anyone (who knows R) how to exactly recreate what the user was seeing when they hit the button.

# Primer on Python for R Users -[reticulate vignette](https://rstudio.github.io/reticulate/articles/python_primer.html)

## Whitespace

"Whitespace matters in Python. In R, expressions are grouped into a code block with {}. In Python, that is done by making the expressions share an indentation level."

## Lists

"In R, the list() is a container you can use to organize R objects. R’s list() is feature packed, and **there is no single direct equivalent in Python** that supports all the same features. Instead there are (at least) 4 different Python container types you need to be aware of: lists, dictionaries, tuples, and sets."

"The most important thing to know about Python lists is that they are **modified in place**."

This is in contrast to R which has "copy-on-modify" behaviour.

```{python}
#| label: python-modify-in-place
#| include: TRUE

# Python
x = [1, 2, 3]

# `y` and `x` now refer to the same list
y = x

# Add 4 onto x will also add 4 to y
x.append(4)

print(x)

print(y)

```

```{r}
#| label: r-copy-on-modify
#| include: TRUE

# R
x <- list(1, 2, 3)

# The list has now been copied to refer to y ("copy-on-modify" behaviour)
y <- x

# Adding 4 onto x doesn't change y
x[4] <- 4

x

y

```

## Indexing

Python indexing is 0-based, whereas R is 1-based.

```{python}
#| label: python-indexing
#| include: TRUE

# Python
x = [1,2,3]

x[0]

```

```{r}
#| label: r-indexing
#| include: TRUE

# R
x <- list(1, 2, 3)

x[1]

```

## Dictionaries

"Dictionaries are most similar to R environments. They are a container where you can retrieve items by name, though in Python the name (called a key in Python’s parlance) does not need to be a string like in R."

## Functions

"Unlike R functions, the last value in a function is not automatically returned. Python requires an explicit return statement."

## Classes

"One could argue that **in R, the preeminent unit of composition for code is the function, and in Python, it’s the class**."

"classes are typically CamelCase, and functions are typically snake_case."

"Python typically indicates that something is special by wrapping the name in double underscores. A special double-underscore-wrapped token is commonly called a “dunder”."

"Functions defined inside a class code block are called methods"

"In R, authors can bundle their code into shareable extensions called R packages, and R users can access objects from R packages via library() or ::. In Python, authors bundle code into modules, and users access modules using import."

"R users generally don’t need to be aware of the difference between integers and floating point numbers, but that’s not the case in Python."

# [A History of the GUI](https://arstechnica.com/features/2005/05/gui/)

1968: Douglas Engelbart demos the first computer with a GUI and mouse

1973: Xerox PARC makes the Xerox Alto. This included many of the standards of 
personal computing: a mouse as an arrowhead, different overlapping windows that 
could be selected, icons etc. Xerox never sold the Xerox Alto though - madness.

1976: Steve Jobs begins Apple.

1981: Xerox start selling the Xerox Star 8010.

1983: Apple Lisa: trash can icon, greying out things you can’t select, double 
clicking, drag and drop.

1984: Apple Maccintosh.

1985: Microsoft Windows released. Steve Jobs leaves Apple.

1987: Microsoft releases Windows 2.0 and Apple (unsuccessfully) tries to sue 
them for copying many aspects of Apple GUIs.

“As the 90s began, other personal computing platforms fell off sharply in 
popularity, leaving only Windows and the Macintosh as the survivors of the 
GUI wars.”

# Joe Cheng - [Shiny x AI](https://posit.co/blog/five-highlights-from-posit-conf-2024/)

You can have a Shiny dashboard with a chatbot - the user types in what they
want and the chatbot writes SQL to answer the question.

SQL is easy for large language models to write.

Just being a user of LLMs like ChatGPT is not enough to have an informed opinion
about them - you have to code with them.

The view of LLMs as "stochastic parrots" may be true, but it isn't helpful
when it comes to using and working with them.

# "The Future of Interactive Graphics in R" - Hadley Wickham [Google talks 2011](https://youtu.be/iSXNfZESR5I)

Hadley Wickham started working in the lattice package to make plots, and made
ggplot2 because he got frustrated.

The grammar of graphics already existed as a concept, in a textbook.

ggplot development started in 2005, ggplot2 released in 2007.

RStudio was founded in 2011. In 2011 Wickham was working as an assistant professor at
Rice University, Texas.

Before, in 2008, he submitted his PhD at Iowa State University. ggplot2 was 
submitted as part of his PhD thesis.

Then he supervised Garrett Grolemund's PhD (Grolemund co-authored "R for 
Data Science").

Speed and memory have increased in personal computing, but the screen is basically
the same size - so the number of pixels at our disposal are limited.

Pixels are limited, so we need to use interactivity. The stuff he talks about
is very similar to the philosophy under Shiny.

Legends are the hardest part of any graphics system to write.

If graphics take ages to make, then people are unwilling to change them.

# "Practical Tools for Exploring Data and Models" - [Hadley Wickham's PhD - 2008](https://dr.lib.iastate.edu/entities/publication/9210139e-102e-4537-8b6e-7d8197e2f3d8)

"The tools developed in this thesis are firmly based in the philosophy of exploratory data
analysis (Tukey, 1977). With every view of the data, we strive to be both curious and sceptical.
We keep an open mind towards alternative explanations, never believing we have found the
best model"

"As Tukey once said: “numerical quantities focus on
expected values, graphical summaries on unexpected values.”"

Before ggplot2 there was base R and lattice, which both had problems.

He developed reshape as well, then made reshape2, but then that's been 
replaced by tidyr. "reshape2 is superseded: only changes necessary to keep 
it on CRAN will be made. We recommend using tidyr instead" (reshape2 github page").

"This material is based upon work supported by the National Science Foundation 
under Grant No. 0706949."

###Chapter 3: A Layered Grammar of Graphics

"A regular bar chart converted into polar coordinates produces 
another type of graphic: the coxcomb plot, popularised by 
Florence Nightingale (Nightingale, 1857)."

Specific design choices that he made for the default settings of ggplot2:

- Grey background with white gridlines
- "Data points are not plotted next to the margins of the plot."

"What would a poetry of graphics look like?"

I didn't read chapter 4.

### Chapter 5: Conclusions

"The process of data analysis is not a straight line from point A to B, but 
involves much circling back, and looking at the map to see we’ve been and 
where we should go next."

"It is difficult to judge the impact of your work. Unfortunately, because of 
the way that CRAN is
set up, it is not possible to know exactly how many times my packages 
have been downloaded.
However, last month around 1,600 people viewed package related 
pages on my website and 18
people emailed me a question about one of my packages"

# Jenny Bryan [How to name files](https://www.youtube.com/watch?v=ES1LTlnpLMk)

Pick a convention - it doesn't matter which one, just **pick one**.

Filenames should be machine readable, human readable and sortable.

"Thou shalt get only as creative with file naming as thine skill with 
regular expressions."

Embrace the slug: "slugs" are the last section of a URL which give you an 
idea of what the page shows. Slugs are good for telling people, not computers,
what code does.

For dates **use ISO 8601**. 

# References

::: {#refs}
:::
