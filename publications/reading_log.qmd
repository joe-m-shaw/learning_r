---
title: "Reading Log"
author: "Joe Shaw"
format: html
bibliography: references.bib
csl: harvard-manchester-metropolitan-university.csl
---

# "Excuse Me, Do You Have a Moment to Talk About Version Control?" [@bryan2018]

"Git was built neither for the exact usage described here, nor for broad usability. You will undoubtedly notice this, so it is best to know in advance."

"Git is a version control system. Its original purpose was to help groups of developers work collaboratively on big software projects. Git manages the evolution of a set of files—called a repository or repo—in a sane, highly structured way. It is like the “Track Changes” feature from Microsoft Word, but more rigorous, powerful, and scaled up to multiple files."

"Many people who do not use Git unwittingly reinvent a poor man’s version of it"

"With informal version control, contributors create derivative copies of iris.R, decorating the file name with initials, dates, and other descriptors. Even when working alone, this leads to multiple versions of iris.R of indeterminate relatedness (Figure 1(a)). In collaborative settings based on email distribution, the original file swiftly becomes part of a complicated phylogeny that no amount of “Track changes” and good intentions can resolve"

"GitHub is like DropBox or Google Drive, but more structured, powerful, and programmatic."

"There is a taboo against committing derived products, inherited from Git’s software development roots, because the typical product in that context is a platform-specific executable. This rationale, however, does not apply to many data science products. Rendered reports, figures, and cleaned data are often extremely valuable to others. Make them readily available."

"If a file is binary, such as a Word document or Excel spreadsheet, you will not get human-readable diffs anyway, nor can GitHub display the content in the browser."

"What is a merge conflict? It happens when Git cannot be certain how to jointly apply the diffs from two different commits to their common parent. At each location of conflict, you must pick one version or the other – or create a hybrid—and mark it as resolved."

# "Packaging data analytical work reproducibly using R (and friends)" [@marwick2018]

"Virtually all researchers use computers as a central tool in their workflow. However, our
formal education rarely includes any training in how to organise our computer files to make
it easy to reproduce results and share our entire analysis pipeline with others."

"Although the R packaging system is traditionally a method for sharing statistical
methods, we claim that R packages are suitable for use as research compendia that can
help improve computational reproducibility."

Compendium: a short but complete summary.

"Once you are ready to share your compendium, the best way is to archive a specific
commit at a repository that issues persistent URLs, such as a Digital Object Identifier DOI), for file archives (e.g. osf.io, figshare.com or zenodo.org). DOIs are designed to be
far more persistent than other URLs, which often break as web pages change over time."

"While CRAN is one of the biggest and best-known systems for archiving and distributing
R packages, we do not recommend it for research compendium packages. The main reason
that CRAN is not suitable is that it is very strict about the directory structure and contents
for the R packages that it accepts."

This is really useful paper. The premise is that structuring scientific research projects as if they were R packages leads to more reproducible research. This also makes sense in the context of laboratory test validations: what I want is a clear structure to organise a project so that I can put the entire thing somewhere public and say "this is what I did". Their term for this is a "research compendium": the summary of the entire project.

The paper also includes this Github template: https://github.com/cboettig/template

The template is for how to structure an academic paper like an R package, with these folders:

- **R**: contains all functions as .R files.

- **man**: contains documentation for functions using roxygen2.

- **tests**: contains all the tests run during package building.

- **vignettes**: the place for the actual manuscript as a markdown files (RMarkdown, Quarto etc) - this means the manuscript and analysis are fused together as one.

# "Welcome to the Tidyverse" [@wickham2019]

"At a high level, the tidyverse is a language for solving data science challenges with R code. Its
primary goal is to facilitate a conversation between a human and a computer about data."

"Non-core packages are installed with install.packages("tidyverse"), but are not at-
tached by library(tidyverse)." - this explains why you have to use library(lubdridate) - lubridate is technically in the tidyverse but is non-core.

"There is one particularly important principle that we want to call out here: the tidyverse is fundamentally  human centred. That is, the tidyverse is designed to support the activities of a human data analyst, so to be effective tool builders, we must explicitly recognise and acknowledge the strengths and weaknesses of human cognition."

"The tidyverse is not just the collection of packages — it is also the community of people who use them. We want the tidyverse to be a diverse, inclusive, and welcoming community."

# Novo Nordisk's Journey to an R based FDA Submission - [YouTube]()

R packages are great, but they present issues for good practice when it comes to pharmaceutical submissions. This is because pharmaceutical submissions are usually submitted in SAS, and changing the format means learning for the submitter and the regulatory body reviewing the work.

They set up a Shiny interface for people to request an R package to be made available within the company's R environment.

### Acronyms and terms:

**Novo Nordisk:** pharmaceutical company

**GxP:** "good practice" (i.e GMP - Good Manufacturing Practice)

**SAS:** statistical language normally used for pharmaceutical submissions (Statistical Analysis System).

**Azure (Microsoft Azure):** cloud-computing service provided by Microsoft.

**AWS:** Amazon Web Solutions.

**Kubernetes:** a system for automating software development, initially developed by Google. "Kubernetes" comes from the Greek word for "helmsman" - i.e. Kubernetes steers the ship for you.

**TFL:** Tables, Figures and Listings

**SDTM:** Study Data Tabulation Model 

**ADaM:** Analysis Data Model (see [this link](https://www.certara.com/blog/demystifying-cdisc-sdtm-and-adam/))

# Jenny Bryan "Object of type ‘closure’ is not subsettable" - [Posit](https://posit.co/resources/videos/object-of-type-closure-is-not-subsettable/)

```{r}
#| label: object-type-closure-error
#| error: TRUE
#| include: TRUE
#| warning: FALSE

# You define "dat" as a data frame
dat <- data.frame(x = 1, y = 2)

# You forget that you named it "dat" and instead think you named it "df".
# "df" is actually a function, so you're asking R to give you column x of a function (which it can't do)
df$x

```

Rules for debugging errors.

**Restart R regularly**

Use the shortcut to restart R (Control+shift+F10), rather than using rm(list = ls()) - some things will still persist after running rm(list=ls()) because it only clears the environment.
For example, library(dplyr) will mean that dplyr remains attached even after the environment is cleared.

Restarting R works best when you have the options set to not save or reload the workspace.

**Reprex**

Create small reproducible examples (reprexes).

The distinction between beginners and experts is how they respond to bugs. Experts run small experiments to pick apart problems.

The problem usually lies in the difference between what you *think* you are doing, and what you are *actually* doing.

"If you are trying to find a needle in a haystack, try looking in a smaller haystack" - make the reproducible example *minimal*.

Define the data (in-line) rather than having private data that you run. Simplify the data to the minimum required to replicate the error message.

Don't attach additional packages that aren't necessary to creating the error.

Making a reprex is a way to help you solve your own problem.

**Debug**

Debugging really has 3 modes: traceback (the death certificate), options(error = recover) (the post-mortem) and browser() (resurrecting the dead to establish what happened).

browser() allows you run the code line by line and watch how the environment changes. You can also change the identity of variables mid-way through, if you have a theory about why the error is occurring (if the error then dissapears, you've found the cause).

Hit capital Q (cpaslock + q) to get out of the browser debugger.

**Deter**

After debugging, add an assertion to your code to catch the error in future.

Write error messages for humans. "Object of type closure is not subsettable" is less understandable than "Can't subset a function".

Build things in a way so that when they break it is clear why.

# References

::: {#refs}
:::
